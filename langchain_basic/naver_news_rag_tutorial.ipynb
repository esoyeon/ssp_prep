{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 🚀 네이버 뉴스 기반 한국어 RAG 튜토리얼\n",
        "\n",
        "## 📚 학습 목표\n",
        "이 튜토리얼을 통해 다음을 배우게 됩니다:\n",
        "\n",
        "1. **RAG(Retrieval-Augmented Generation)의 기본 개념**\n",
        "2. **LangChain을 활용한 RAG 시스템 구축**\n",
        "3. **한국어 텍스트 처리 및 임베딩**\n",
        "4. **네이버 뉴스를 활용한 실시간 질답 시스템 개발**\n",
        "\n",
        "## 🔍 RAG란 무엇인가요?\n",
        "\n",
        "**RAG(Retrieval-Augmented Generation)**는 외부 지식 베이스에서 관련 정보를 검색(Retrieval)하여 언어모델의 생성(Generation) 능력을 보강하는 기술입니다.\n",
        "\n",
        "### 🤔 왜 RAG가 필요한가요?\n",
        "\n",
        "1. **최신 정보 부족**: LLM은 훈련 시점 이후의 정보를 모릅니다\n",
        "2. **도메인 특화 지식**: 특정 분야의 전문 지식이 부족할 수 있습니다\n",
        "3. **환각(Hallucination)**: 잘못된 정보를 그럴듯하게 생성할 수 있습니다\n",
        "\n",
        "### ✅ RAG의 장점\n",
        "\n",
        "- 📈 **최신 정보 활용**: 실시간 데이터 반영 가능\n",
        "- 🎯 **정확도 향상**: 검증된 소스에서 정보 추출\n",
        "- 💰 **비용 효율성**: 전체 모델 재훈련 불필요\n",
        "- 🔄 **유연성**: 지식 베이스 쉽게 업데이트 가능\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🏗️ RAG 시스템 아키텍처\n",
        "\n",
        "RAG 시스템은 크게 **2개의 주요 단계**로 구성됩니다:\n",
        "\n",
        "### 📋 1단계: 사전 작업(Pre-processing) - 지식 베이스 구축\n",
        "\n",
        "```\n",
        "[문서] → [분할] → [임베딩] → [벡터DB 저장]\n",
        "```\n",
        "\n",
        "1. **문서 로드**: 원본 문서나 데이터를 시스템에 로드\n",
        "2. **텍스트 분할**: 큰 문서를 작은 청크(Chunk)로 나누기\n",
        "3. **임베딩**: 텍스트를 벡터 형태로 변환\n",
        "4. **저장**: 벡터 데이터베이스에 저장\n",
        "\n",
        "### 🔄 2단계: 실행 시간(Runtime) - 질의응답 수행\n",
        "\n",
        "```\n",
        "[질문] → [검색] → [프롬프트 생성] → [LLM] → [답변]\n",
        "```\n",
        "\n",
        "1. **질문 입력**: 사용자가 질문을 입력\n",
        "2. **관련 문서 검색**: 벡터 유사도를 기반으로 관련 문서 검색\n",
        "3. **프롬프트 생성**: 검색된 문서와 질문을 조합하여 프롬프트 생성\n",
        "4. **LLM 생성**: 언어모델이 최종 답변 생성\n",
        "\n",
        "---\n",
        "\n",
        "## 🛠️ 실습 환경 준비\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 📦 필요한 라이브러리 설치\n",
        "\n",
        "먼저 필요한 라이브러리들을 설치해보겠습니다. 각 라이브러리의 역할을 알아봅시다:\n",
        "\n",
        "- **langchain**: RAG 파이프라인 구축을 위한 핵심 프레임워크\n",
        "- **langchain-openai**: OpenAI API 연동\n",
        "- **langchain-community**: 커뮤니티에서 제공하는 추가 기능들\n",
        "- **beautifulsoup4**: 웹 페이지 파싱 (네이버 뉴스 크롤링용)\n",
        "- **faiss-cpu**: 고속 벡터 유사도 검색 엔진\n",
        "- **python-dotenv**: 환경변수 관리\n",
        "\n",
        "실제 환경에서는 아래 명령어로 설치하세요:\n",
        "```bash\n",
        "pip install langchain langchain-openai langchain-community langchain-text-splitters\n",
        "pip install beautifulsoup4 faiss-cpu python-dotenv\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 🔧 환경 설정 및 라이브러리 import\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "import bs4\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
        "\n",
        "print(\"✅ 모든 라이브러리가 성공적으로 import되었습니다!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 🔑 API 키 설정\n",
        "\n",
        "OpenAI API를 사용하기 위해 API 키를 설정해야 합니다.\n",
        "\n",
        "**⚠️ 중요**: \n",
        "- OpenAI API 키는 [https://platform.openai.com/api-keys](https://platform.openai.com/api-keys)에서 발급받을 수 있습니다.\n",
        "- `.env` 파일에 `OPENAI_API_KEY=your_api_key_here` 형태로 저장하세요.\n",
        "- **절대 코드에 직접 API 키를 넣지 마세요!** (보안상 위험합니다)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# API 키 로드\n",
        "load_dotenv()\n",
        "\n",
        "# API 키가 제대로 설정되었는지 확인\n",
        "if os.getenv(\"OPENAI_API_KEY\"):\n",
        "    print(\"✅ OpenAI API 키가 정상적으로 로드되었습니다!\")\n",
        "else:\n",
        "    print(\"❌ OpenAI API 키가 설정되지 않았습니다.\")\n",
        "    print(\"💡 .env 파일에 OPENAI_API_KEY=your_api_key 를 추가하세요.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 🏁 RAG 파이프라인 구축 시작!\n",
        "\n",
        "이제 본격적으로 RAG 시스템을 단계별로 구축해보겠습니다.\n",
        "\n",
        "## 📰 1단계: 문서 로드 (Document Loading)\n",
        "\n",
        "첫 번째 단계는 네이버 뉴스 기사를 로드하는 것입니다.\n",
        "\n",
        "### 🔍 WebBaseLoader 이해하기\n",
        "\n",
        "`WebBaseLoader`는 웹 페이지의 내용을 추출하는 도구입니다. 네이버 뉴스 페이지에서 실제 기사 내용만 추출하기 위해 CSS 선택자를 사용합니다.\n",
        "\n",
        "**주요 매개변수:**\n",
        "- `web_paths`: 크롤링할 웹페이지 URL\n",
        "- `bs_kwargs`: BeautifulSoup 설정 (파싱할 HTML 요소 지정)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 네이버 뉴스 URL (예시 - 실제 사용시 최신 뉴스로 변경하세요)\n",
        "news_url = \"https://n.news.naver.com/article/437/0000378416\"\n",
        "\n",
        "print(f\"📰 로딩할 뉴스 URL: {news_url}\")\n",
        "print(\"🔄 뉴스 기사를 로딩 중입니다...\")\n",
        "\n",
        "# WebBaseLoader 설정\n",
        "# 네이버 뉴스의 제목과 본문만 추출하기 위한 CSS 선택자 설정\n",
        "loader = WebBaseLoader(\n",
        "    web_paths=(news_url,),\n",
        "    bs_kwargs=dict(\n",
        "        parse_only=bs4.SoupStrainer(\n",
        "            \"div\",\n",
        "            attrs={\"class\": [\"newsct_article _article_body\", \"media_end_head_title\"]},\n",
        "        )\n",
        "    ),\n",
        ")\n",
        "\n",
        "# 문서 로드 실행\n",
        "docs = loader.load()\n",
        "\n",
        "print(f\"✅ 문서 로드 완료! 총 {len(docs)}개 문서가 로드되었습니다.\")\n",
        "\n",
        "# 로드된 문서의 일부 내용 확인\n",
        "if docs:\n",
        "    print(\"\\n📄 로드된 문서 미리보기:\")\n",
        "    print(\"-\" * 50)\n",
        "    print(docs[0].page_content[:300] + \"...\")\n",
        "    print(\"-\" * 50)\n",
        "    print(f\"📊 전체 문서 길이: {len(docs[0].page_content)} 문자\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ✂️ 2단계: 텍스트 분할 (Text Splitting)\n",
        "\n",
        "### 🤔 왜 텍스트를 분할해야 할까요?\n",
        "\n",
        "1. **토큰 제한**: LLM은 한 번에 처리할 수 있는 토큰 수가 제한되어 있습니다\n",
        "2. **검색 정확도**: 작은 청크일수록 더 정확한 검색이 가능합니다\n",
        "3. **의미 단위**: 관련된 내용끼리 묶어서 처리하면 더 좋은 결과를 얻을 수 있습니다\n",
        "\n",
        "### 🔧 RecursiveCharacterTextSplitter 매개변수\n",
        "\n",
        "- **chunk_size**: 각 청크의 최대 문자 수\n",
        "- **chunk_overlap**: 인접한 청크 간 겹치는 문자 수 (문맥 연결을 위해)\n",
        "\n",
        "**💡 팁**: \n",
        "- chunk_size가 클수록: 더 많은 문맥 정보, 하지만 검색 정확도 감소\n",
        "- chunk_size가 작을수록: 정확한 검색, 하지만 문맥 정보 부족\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 텍스트 분할기 설정\n",
        "chunk_size = 1000  # 각 청크의 최대 크기\n",
        "chunk_overlap = 100  # 청크 간 겹치는 부분\n",
        "\n",
        "print(f\"🔧 텍스트 분할 설정:\")\n",
        "print(f\"   - 청크 크기: {chunk_size} 문자\")\n",
        "print(f\"   - 겹침: {chunk_overlap} 문자\")\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=chunk_size,\n",
        "    chunk_overlap=chunk_overlap\n",
        ")\n",
        "\n",
        "# 문서 분할 실행\n",
        "print(\"\\n✂️ 문서를 청크로 분할하는 중...\")\n",
        "splits = text_splitter.split_documents(docs)\n",
        "\n",
        "print(f\"✅ 분할 완료! 총 {len(splits)}개의 청크가 생성되었습니다.\")\n",
        "\n",
        "# 분할된 청크들 살펴보기\n",
        "print(\"\\n📝 생성된 청크들 미리보기:\")\n",
        "for i, chunk in enumerate(splits[:3]):  # 처음 3개 청크만 보기\n",
        "    print(f\"\\n--- 청크 {i+1} ---\")\n",
        "    print(f\"길이: {len(chunk.page_content)} 문자\")\n",
        "    print(f\"내용: {chunk.page_content[:150]}...\")\n",
        "\n",
        "print(f\"\\n📊 청크 크기 분포:\")\n",
        "chunk_lengths = [len(chunk.page_content) for chunk in splits]\n",
        "print(f\"   - 최소: {min(chunk_lengths)} 문자\")\n",
        "print(f\"   - 최대: {max(chunk_lengths)} 문자\")\n",
        "print(f\"   - 평균: {sum(chunk_lengths)/len(chunk_lengths):.0f} 문자\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🔢 3단계: 임베딩 생성 (Embedding)\n",
        "\n",
        "### 🧠 임베딩이란?\n",
        "\n",
        "임베딩은 텍스트를 **숫자 벡터로 변환**하는 과정입니다. 컴퓨터는 숫자만 이해할 수 있기 때문에, 텍스트의 의미를 벡터 공간에서 표현합니다.\n",
        "\n",
        "**예시:**\n",
        "- \"사과\" → [0.1, 0.8, 0.3, ...]\n",
        "- \"과일\" → [0.2, 0.7, 0.4, ...]\n",
        "- \"자동차\" → [0.9, 0.1, 0.2, ...]\n",
        "\n",
        "유사한 의미를 가진 단어들은 벡터 공간에서 **가까운 위치**에 놓입니다.\n",
        "\n",
        "### 🔍 OpenAI 임베딩의 특징\n",
        "\n",
        "- **높은 품질**: 다양한 언어와 도메인에서 우수한 성능\n",
        "- **다차원**: 보통 1536차원의 벡터로 표현\n",
        "- **한국어 지원**: 한국어 텍스트도 잘 처리합니다\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# OpenAI 임베딩 모델 초기화\n",
        "print(\"🔢 임베딩 모델을 초기화하는 중...\")\n",
        "embeddings = OpenAIEmbeddings()\n",
        "\n",
        "print(\"✅ OpenAI 임베딩 모델이 준비되었습니다!\")\n",
        "print(\"📝 사용 모델: text-embedding-ada-002\")\n",
        "\n",
        "# 임베딩 테스트 (간단한 예시)\n",
        "test_text = \"안녕하세요, 한국어 임베딩 테스트입니다.\"\n",
        "print(f\"\\n🧪 임베딩 테스트 문장: '{test_text}'\")\n",
        "\n",
        "# 실제로 임베딩 해보기 (시간이 조금 걸릴 수 있습니다)\n",
        "try:\n",
        "    test_embedding = embeddings.embed_query(test_text)\n",
        "    print(f\"✅ 임베딩 생성 성공!\")\n",
        "    print(f\"📊 벡터 차원: {len(test_embedding)}\")\n",
        "    print(f\"🔢 벡터 일부 (처음 5개): {test_embedding[:5]}\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ 임베딩 생성 실패: {e}\")\n",
        "    print(\"💡 API 키를 확인해주세요.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 💾 4단계: 벡터 저장소 생성 (Vector Store)\n",
        "\n",
        "### 🗃️ 벡터 저장소란?\n",
        "\n",
        "벡터 저장소는 임베딩된 텍스트 벡터들을 **효율적으로 저장하고 검색**할 수 있는 데이터베이스입니다.\n",
        "\n",
        "### 🚀 FAISS의 장점\n",
        "\n",
        "**FAISS(Facebook AI Similarity Search)**는 Meta에서 개발한 고성능 벡터 검색 라이브러리입니다:\n",
        "\n",
        "- ⚡ **빠른 검색**: 수백만 개의 벡터에서도 밀리초 단위 검색\n",
        "- 🎯 **높은 정확도**: 코사인 유사도 기반 정확한 검색\n",
        "- 💻 **메모리 효율성**: 대용량 데이터도 효율적으로 처리\n",
        "- 🔄 **쉬운 사용**: LangChain과 완벽 호환\n",
        "\n",
        "### 🔍 검색 원리\n",
        "\n",
        "1. 사용자 질문을 임베딩으로 변환\n",
        "2. 저장된 벡터들과 유사도 계산  \n",
        "3. 가장 유사한 상위 K개 문서 반환\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 벡터 저장소 생성 (시간이 조금 걸릴 수 있습니다)\n",
        "print(\"💾 벡터 저장소 생성 중...\")\n",
        "print(\"   - 모든 텍스트 청크를 임베딩으로 변환하고 있습니다...\")\n",
        "print(\"   - 이 과정은 텍스트 양에 따라 1-2분 정도 소요될 수 있습니다...\")\n",
        "\n",
        "try:\n",
        "    # FAISS 벡터스토어 생성\n",
        "    vectorstore = FAISS.from_documents(documents=splits, embedding=embeddings)\n",
        "    \n",
        "    print(\"✅ 벡터 저장소 생성 완료!\")\n",
        "    print(f\"📊 저장된 문서 수: {len(splits)}개\")\n",
        "    \n",
        "    # 간단한 검색 테스트\n",
        "    print(\"\\n🔍 벡터 저장소 검색 테스트:\")\n",
        "    test_query = \"정부 정책\"\n",
        "    search_results = vectorstore.similarity_search(test_query, k=2)\n",
        "    \n",
        "    print(f\"검색어: '{test_query}'\")\n",
        "    print(f\"검색 결과: {len(search_results)}개 문서 발견\")\n",
        "    \n",
        "    for i, result in enumerate(search_results):\n",
        "        print(f\"\\n--- 검색 결과 {i+1} ---\")\n",
        "        print(f\"내용: {result.page_content[:100]}...\")\n",
        "        \n",
        "except Exception as e:\n",
        "    print(f\"❌ 벡터 저장소 생성 실패: {e}\")\n",
        "    print(\"💡 API 키와 인터넷 연결을 확인해주세요.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🔍 5단계: 검색기 생성 (Retriever)\n",
        "\n",
        "### 🎯 검색기의 역할\n",
        "\n",
        "검색기는 사용자의 질문과 가장 관련성 높은 문서 청크들을 찾아주는 중요한 역할을 합니다.\n",
        "\n",
        "### ⚙️ 검색기 설정 옵션\n",
        "\n",
        "- **k**: 반환할 문서의 개수 (기본값: 4)\n",
        "- **search_type**: 검색 유형\n",
        "  - `\"similarity\"`: 유사도 기반 검색 (기본값)\n",
        "  - `\"mmr\"`: 최대 한계 적합성 (다양성 고려)\n",
        "- **score_threshold**: 유사도 임계값 (이 값 이상의 문서만 반환)\n",
        "\n",
        "### 💡 검색 성능 튜닝 팁\n",
        "\n",
        "- **k값이 클수록**: 더 많은 정보, 하지만 노이즈 증가 가능\n",
        "- **k값이 작을수록**: 정확한 정보, 하지만 정보 부족 가능\n",
        "- **일반적으로 3-5개가 적당합니다**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 검색기 생성\n",
        "print(\"🔍 검색기 생성 중...\")\n",
        "\n",
        "# 기본 설정으로 검색기 생성\n",
        "retriever = vectorstore.as_retriever()\n",
        "\n",
        "print(\"✅ 기본 검색기 생성 완료!\")\n",
        "print(\"📋 기본 설정:\")\n",
        "print(\"   - 검색 방식: 유사도 기반\")\n",
        "print(\"   - 반환 문서 수: 4개\")\n",
        "\n",
        "# 커스텀 설정으로 검색기 생성 (선택사항)\n",
        "print(\"\\n🔧 커스텀 검색기도 만들어보겠습니다:\")\n",
        "custom_retriever = vectorstore.as_retriever(\n",
        "    search_type=\"similarity\",\n",
        "    search_kwargs={\"k\": 3}  # 3개 문서만 반환\n",
        ")\n",
        "\n",
        "print(\"✅ 커스텀 검색기 생성 완료!\")\n",
        "print(\"📋 커스텀 설정:\")\n",
        "print(\"   - 검색 방식: 유사도 기반\")\n",
        "print(\"   - 반환 문서 수: 3개\")\n",
        "\n",
        "# 검색기 테스트\n",
        "print(\"\\n🧪 검색기 성능 테스트:\")\n",
        "test_questions = [\n",
        "    \"이 기사의 주요 내용은 무엇인가요?\",\n",
        "    \"정부의 정책은 무엇인가요?\",\n",
        "    \"주요 인물은 누구인가요?\"\n",
        "]\n",
        "\n",
        "for question in test_questions:\n",
        "    print(f\"\\n❓ 질문: {question}\")\n",
        "    \n",
        "    # 기본 검색기로 검색\n",
        "    results = retriever.invoke(question)\n",
        "    print(f\"🔍 기본 검색기 결과: {len(results)}개 문서\")\n",
        "    \n",
        "    # 첫 번째 결과만 미리보기\n",
        "    if results:\n",
        "        print(f\"📄 첫 번째 문서: {results[0].page_content[:80]}...\")\n",
        "\n",
        "print(\"\\n✅ 검색기 테스트 완료!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 📝 6단계: 프롬프트 생성 (Prompt Engineering)\n",
        "\n",
        "### 🎭 프롬프트의 중요성\n",
        "\n",
        "프롬프트는 AI에게 **\"어떻게 답변할지\"**를 알려주는 지침서입니다. 좋은 프롬프트는 다음을 포함해야 합니다:\n",
        "\n",
        "1. **명확한 역할 정의**: AI가 어떤 역할을 해야 하는지\n",
        "2. **컨텍스트 활용 지침**: 검색된 문서를 어떻게 사용할지  \n",
        "3. **답변 형식 가이드**: 어떤 형태로 답변할지\n",
        "4. **제약사항**: 모르는 경우 어떻게 답할지\n",
        "\n",
        "### 🇰🇷 한국어 프롬프트 설계 포인트\n",
        "\n",
        "- **정중한 톤**: 한국어의 존댓말 문화 반영\n",
        "- **기술 용어 보존**: 번역하지 말고 원어 그대로 사용\n",
        "- **명확한 안내**: 정보가 없을 때의 대응 방식 명시\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 한국어 RAG를 위한 프롬프트 템플릿 생성\n",
        "print(\"📝 한국어 RAG 프롬프트 생성 중...\")\n",
        "\n",
        "prompt = PromptTemplate.from_template(\n",
        "    \"\"\"당신은 질문-답변(Question-Answering)을 수행하는 친절한 AI 어시스턴트입니다. \n",
        "당신의 임무는 주어진 문맥(context)에서 주어진 질문(question)에 답하는 것입니다.\n",
        "\n",
        "검색된 다음 문맥(context)을 사용하여 질문(question)에 답하세요. \n",
        "만약, 주어진 문맥(context)에서 답을 찾을 수 없다면, \n",
        "`주어진 정보에서 질문에 대한 정보를 찾을 수 없습니다`라고 답하세요.\n",
        "\n",
        "한글로 답변해 주세요. 단, 기술적인 용어나 이름은 번역하지 않고 그대로 사용해 주세요.\n",
        "\n",
        "#Question: \n",
        "{question} \n",
        "\n",
        "#Context: \n",
        "{context} \n",
        "\n",
        "#Answer:\"\"\"\n",
        ")\n",
        "\n",
        "print(\"✅ 프롬프트 템플릿 생성 완료!\")\n",
        "\n",
        "# 프롬프트 구조 분석\n",
        "print(\"\\n📋 프롬프트 구조 분석:\")\n",
        "print(\"1. 역할 정의: '친절한 AI 어시스턴트'\")\n",
        "print(\"2. 임무 설명: '문맥에서 질문에 답하기'\")\n",
        "print(\"3. 사용 지침: '검색된 문맥 활용'\")\n",
        "print(\"4. 제약사항: '모르면 솔직히 말하기'\")\n",
        "print(\"5. 언어 설정: '한글 답변, 기술용어 보존'\")\n",
        "print(\"6. 입력 변수: question(질문), context(문맥)\")\n",
        "\n",
        "# 프롬프트 템플릿 미리보기\n",
        "sample_question = \"이 뉴스의 주요 내용은 무엇인가요?\"\n",
        "sample_context = \"샘플 문맥입니다...\"\n",
        "\n",
        "print(f\"\\n🔍 프롬프트 템플릿 미리보기:\")\n",
        "print(\"-\" * 50)\n",
        "formatted_prompt = prompt.format(question=sample_question, context=sample_context)\n",
        "print(formatted_prompt)\n",
        "print(\"-\" * 50)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🤖 7단계: 언어모델 설정 (LLM)\n",
        "\n",
        "### 🧠 ChatOpenAI 모델 선택\n",
        "\n",
        "여러 OpenAI 모델 중에서 우리의 용도에 맞는 모델을 선택해보겠습니다:\n",
        "\n",
        "| 모델 | 특징 | 속도 | 비용 | 추천 용도 |\n",
        "|------|------|------|------|-----------|\n",
        "| **gpt-4o-mini** | 높은 성능, 저렴한 비용 | 빠름 | 저렴 | ✅ **RAG에 최적** |\n",
        "| gpt-4o | 최고 성능 | 보통 | 비싼편 | 복잡한 추론 |\n",
        "| gpt-3.5-turbo | 기본 성능 | 매우 빠름 | 매우 저렴 | 간단한 대화 |\n",
        "\n",
        "### ⚙️ 주요 매개변수\n",
        "\n",
        "- **model_name**: 사용할 모델 선택\n",
        "- **temperature**: 창의성 조절 (0: 일관적, 1: 창의적)\n",
        "- **max_tokens**: 최대 응답 길이 제한\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 언어모델 설정\n",
        "print(\"🤖 ChatOpenAI 언어모델 설정 중...\")\n",
        "\n",
        "# RAG에 최적화된 설정\n",
        "llm = ChatOpenAI(\n",
        "    model_name=\"gpt-4o-mini\",  # 성능과 비용의 균형이 좋은 모델\n",
        "    temperature=0              # 일관된 답변을 위해 창의성을 낮게 설정\n",
        ")\n",
        "\n",
        "print(\"✅ 언어모델 설정 완료!\")\n",
        "print(\"📋 설정된 모델 정보:\")\n",
        "print(\"   - 모델: gpt-4o-mini\")\n",
        "print(\"   - Temperature: 0 (일관된 답변)\")\n",
        "print(\"   - 용도: 질문-답변 시스템에 최적화\")\n",
        "\n",
        "# 모델 간단 테스트\n",
        "print(\"\\n🧪 언어모델 테스트:\")\n",
        "test_prompt = \"안녕하세요! 한국어로 간단하게 자기소개를 해주세요.\"\n",
        "\n",
        "try:\n",
        "    response = llm.invoke(test_prompt)\n",
        "    print(f\"💬 모델 응답: {response.content}\")\n",
        "    print(\"✅ 언어모델이 정상적으로 작동합니다!\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ 언어모델 테스트 실패: {e}\")\n",
        "    print(\"💡 API 키와 인터넷 연결을 확인해주세요.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🔗 8단계: RAG 체인 생성 (Chain Assembly)\n",
        "\n",
        "### 🎯 체인이란?\n",
        "\n",
        "**체인(Chain)**은 여러 컴포넌트를 연결하여 하나의 파이프라인을 만드는 LangChain의 핵심 개념입니다.\n",
        "\n",
        "### 🔄 우리 RAG 체인의 구조\n",
        "\n",
        "```\n",
        "질문 입력 → 검색기 → 프롬프트 → LLM → 출력 파서 → 최종 답변\n",
        "```\n",
        "\n",
        "각 단계의 역할:\n",
        "1. **RunnablePassthrough**: 질문을 그대로 전달\n",
        "2. **retriever**: 관련 문서 검색\n",
        "3. **prompt**: 검색된 문서와 질문을 조합\n",
        "4. **llm**: AI 모델이 답변 생성\n",
        "5. **StrOutputParser**: 출력을 문자열로 변환\n",
        "\n",
        "### 🧩 LCEL (LangChain Expression Language)\n",
        "\n",
        "`|` 연산자를 사용하여 컴포넌트들을 파이프라인처럼 연결합니다:\n",
        "\n",
        "```python\n",
        "chain = input | component1 | component2 | output\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# RAG 체인 생성 - 모든 컴포넌트를 연결합니다!\n",
        "print(\"🔗 RAG 체인 생성 중...\")\n",
        "\n",
        "# 체인 구성: 각 단계를 파이프라인으로 연결\n",
        "rag_chain = (\n",
        "    {\"context\": retriever, \"question\": RunnablePassthrough()}  # 입력: 검색된 문서 + 질문\n",
        "    | prompt                                                   # 프롬프트 템플릿 적용\n",
        "    | llm                                                      # 언어모델로 답변 생성\n",
        "    | StrOutputParser()                                        # 결과를 문자열로 변환\n",
        ")\n",
        "\n",
        "print(\"✅ RAG 체인 생성 완료!\")\n",
        "\n",
        "# 체인 구조 설명\n",
        "print(\"\\n📋 생성된 RAG 체인 구조:\")\n",
        "print(\"1. 📥 입력: 사용자 질문\")\n",
        "print(\"2. 🔍 검색: retriever가 관련 문서 검색\")\n",
        "print(\"3. 📝 프롬프트: 검색된 문서와 질문을 템플릿에 삽입\")\n",
        "print(\"4. 🤖 생성: LLM이 답변 생성\")\n",
        "print(\"5. 📤 출력: 문자열 형태로 최종 답변 반환\")\n",
        "\n",
        "print(\"\\n🎉 축하합니다! RAG 시스템이 완성되었습니다!\")\n",
        "print(\"이제 네이버 뉴스 기사에 대해 질문할 수 있습니다.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 🚀 RAG 시스템 테스트하기!\n",
        "\n",
        "이제 완성된 RAG 시스템을 실제로 테스트해보겠습니다. \n",
        "\n",
        "### 🎯 테스트 계획\n",
        "\n",
        "1. **기본 질문들**: 뉴스 내용에 대한 일반적인 질문\n",
        "2. **상세 질문들**: 특정 정보를 찾는 질문  \n",
        "3. **범위 밖 질문**: 뉴스에 없는 내용에 대한 질문 (환각 테스트)\n",
        "\n",
        "### 💡 주의사항\n",
        "\n",
        "- 첫 번째 실행 시 조금 시간이 걸릴 수 있습니다\n",
        "- API 요금이 발생할 수 있으니 적당히 테스트하세요\n",
        "- 결과가 만족스럽지 않으면 프롬프트나 검색 설정을 조정해보세요\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 🎯 기본 질문 테스트\n",
        "print(\"🎯 기본 질문들로 RAG 시스템을 테스트해보겠습니다!\\n\")\n",
        "\n",
        "basic_questions = [\n",
        "    \"이 기사의 주요 내용을 요약해주세요.\",\n",
        "    \"기사에서 언급된 주요 인물이나 기관은 누구인가요?\",\n",
        "    \"이 기사가 다루는 주요 이슈는 무엇인가요?\"\n",
        "]\n",
        "\n",
        "for i, question in enumerate(basic_questions, 1):\n",
        "    print(f\"📋 테스트 {i}/3\")\n",
        "    print(f\"❓ 질문: {question}\")\n",
        "    print(\"🔄 답변 생성 중...\")\n",
        "    \n",
        "    try:\n",
        "        # RAG 체인 실행\n",
        "        response = rag_chain.invoke(question)\n",
        "        \n",
        "        print(f\"💬 답변:\")\n",
        "        print(\"-\" * 50)\n",
        "        print(response)\n",
        "        print(\"-\" * 50)\n",
        "        print(\"✅ 답변 생성 완료!\\n\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"❌ 오류 발생: {e}\")\n",
        "        print(\"💡 API 키와 인터넷 연결을 확인해주세요.\\n\")\n",
        "\n",
        "print(\"🎉 기본 질문 테스트가 완료되었습니다!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 🔍 상세 질문 테스트\n",
        "print(\"🔍 더 구체적인 질문들로 테스트해보겠습니다!\\n\")\n",
        "\n",
        "detailed_questions = [\n",
        "    \"기사에서 언급된 구체적인 숫자나 통계가 있나요?\",\n",
        "    \"정부나 공공기관의 정책이 언급되었나요?\",\n",
        "    \"이 기사는 언제 작성되었고, 어떤 배경에서 나온 내용인가요?\"\n",
        "]\n",
        "\n",
        "for i, question in enumerate(detailed_questions, 1):\n",
        "    print(f\"📋 상세 테스트 {i}/3\")\n",
        "    print(f\"❓ 질문: {question}\")\n",
        "    print(\"🔄 답변 생성 중...\")\n",
        "    \n",
        "    try:\n",
        "        response = rag_chain.invoke(question)\n",
        "        \n",
        "        print(f\"💬 답변:\")\n",
        "        print(\"-\" * 50)\n",
        "        print(response)\n",
        "        print(\"-\" * 50)\n",
        "        print(\"✅ 답변 생성 완료!\\n\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"❌ 오류 발생: {e}\")\n",
        "        print(\"💡 잠시 후 다시 시도해보세요.\\n\")\n",
        "\n",
        "print(\"🎉 상세 질문 테스트가 완료되었습니다!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 🚫 환각(Hallucination) 테스트 - 기사에 없는 내용 질문\n",
        "print(\"🚫 환각 테스트: 기사에 없는 내용에 대해 질문해보겠습니다!\\n\")\n",
        "print(\"💡 좋은 RAG 시스템은 모르는 것에 대해 솔직하게 '모른다'고 답해야 합니다.\")\n",
        "\n",
        "hallucination_questions = [\n",
        "    \"이 기사에서 날씨에 대한 언급이 있나요?\",\n",
        "    \"기사에서 축구나 스포츠에 대한 내용이 언급되었나요?\",\n",
        "    \"작년 동일한 시기의 비교 데이터가 있나요?\"\n",
        "]\n",
        "\n",
        "for i, question in enumerate(hallucination_questions, 1):\n",
        "    print(f\"📋 환각 테스트 {i}/3\")\n",
        "    print(f\"❓ 질문: {question}\")\n",
        "    print(\"🔄 답변 생성 중...\")\n",
        "    \n",
        "    try:\n",
        "        response = rag_chain.invoke(question)\n",
        "        \n",
        "        print(f\"💬 답변:\")\n",
        "        print(\"-\" * 50)\n",
        "        print(response)\n",
        "        print(\"-\" * 50)\n",
        "        \n",
        "        # 응답 분석\n",
        "        if \"주어진 정보에서\" in response or \"찾을 수 없습니다\" in response or \"없습니다\" in response:\n",
        "            print(\"✅ 올바른 응답: 모르는 것에 대해 솔직하게 답했습니다!\")\n",
        "        else:\n",
        "            print(\"⚠️ 주의: 확인이 필요한 응답입니다.\")\n",
        "        \n",
        "        print()\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"❌ 오류 발생: {e}\\n\")\n",
        "\n",
        "print(\"🎉 환각 테스트가 완료되었습니다!\")\n",
        "print(\"💡 RAG 시스템이 얼마나 신뢰할 수 있는지 확인해보셨나요?\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🎨 대화형 RAG 시스템 체험\n",
        "\n",
        "이제 직접 질문을 입력해서 RAG 시스템과 대화해볼 수 있는 간단한 인터페이스를 만들어보겠습니다!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 🎨 대화형 RAG 시스템\n",
        "def interactive_rag():\n",
        "    \"\"\"대화형 RAG 시스템 - 직접 질문해보세요!\"\"\"\n",
        "    print(\"🎉 대화형 RAG 시스템에 오신 것을 환영합니다!\")\n",
        "    print(\"💡 네이버 뉴스 기사에 대해 무엇이든 질문해보세요.\")\n",
        "    print(\"⚠️ '종료' 또는 'quit'를 입력하면 시스템을 종료합니다.\\n\")\n",
        "    \n",
        "    question_count = 0\n",
        "    \n",
        "    while True:\n",
        "        # 사용자 입력 받기\n",
        "        user_question = input(\"❓ 질문을 입력하세요: \").strip()\n",
        "        \n",
        "        # 종료 조건\n",
        "        if user_question.lower() in ['종료', 'quit', 'exit', 'q', '']:\n",
        "            print(\"👋 RAG 시스템을 종료합니다. 감사합니다!\")\n",
        "            break\n",
        "            \n",
        "        question_count += 1\n",
        "        print(f\"\\n📋 질문 #{question_count}\")\n",
        "        print(\"🔄 답변을 생성하고 있습니다...\")\n",
        "        \n",
        "        try:\n",
        "            # RAG 시스템으로 답변 생성\n",
        "            response = rag_chain.invoke(user_question)\n",
        "            \n",
        "            print(f\"\\n🤖 AI 답변:\")\n",
        "            print(\"=\" * 60)\n",
        "            print(response)\n",
        "            print(\"=\" * 60)\n",
        "            \n",
        "            # 만족도 피드백 (선택사항)\n",
        "            feedback = input(\"\\n👍 답변이 도움이 되었나요? (y/n/skip): \").strip().lower()\n",
        "            if feedback == 'y':\n",
        "                print(\"😊 감사합니다! 더 질문해보세요.\")\n",
        "            elif feedback == 'n':\n",
        "                print(\"😅 아쉽네요. 다른 방식으로 질문해보시거나 더 구체적으로 물어보세요.\")\n",
        "            \n",
        "            print(\"-\" * 60)\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"❌ 오류가 발생했습니다: {e}\")\n",
        "            print(\"💡 잠시 후 다시 시도해주세요.\\n\")\n",
        "    \n",
        "    print(f\"\\n📊 세션 통계:\")\n",
        "    print(f\"   - 총 질문 수: {question_count}개\")\n",
        "    print(f\"   - 사용된 뉴스: {news_url}\")\n",
        "\n",
        "# 대화형 시스템 실행\n",
        "print(\"🚀 대화형 RAG 시스템을 시작합니다!\")\n",
        "print(\"💻 아래 셀을 실행하면 직접 질문할 수 있습니다.\")\n",
        "\n",
        "# 주석 해제하면 대화형 모드 시작\n",
        "# interactive_rag()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 🎮 대화형 모드 실행하기\n",
        "# 아래 주석을 해제하고 실행하면 직접 질문할 수 있습니다!\n",
        "\n",
        "# interactive_rag()\n",
        "\n",
        "# 또는 한 번만 질문하고 싶다면:\n",
        "def ask_single_question(question):\n",
        "    \"\"\"한 번만 질문하기\"\"\"\n",
        "    print(f\"❓ 질문: {question}\")\n",
        "    print(\"🔄 답변 생성 중...\")\n",
        "    \n",
        "    try:\n",
        "        response = rag_chain.invoke(question)\n",
        "        print(f\"\\n💬 답변:\")\n",
        "        print(\"-\" * 50)\n",
        "        print(response)\n",
        "        print(\"-\" * 50)\n",
        "        return response\n",
        "    except Exception as e:\n",
        "        print(f\"❌ 오류: {e}\")\n",
        "        return None\n",
        "\n",
        "# 예시: 직접 질문해보기\n",
        "print(\"💡 예시: 직접 질문해보기\")\n",
        "print(\"📝 아래 함수를 사용해서 원하는 질문을 해보세요:\")\n",
        "print(\"ask_single_question('여기에 질문을 입력하세요')\")\n",
        "\n",
        "# 예시 실행 (주석 해제해서 사용하세요)\n",
        "# ask_single_question(\"이 기사의 핵심 메시지는 무엇인가요?\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 🔧 RAG 시스템 개선하기\n",
        "\n",
        "### 🎯 성능 향상 팁\n",
        "\n",
        "RAG 시스템의 성능을 향상시킬 수 있는 다양한 방법들을 알아보겠습니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 🔧 RAG 시스템 성능 향상 기법들\n",
        "\n",
        "print(\"🎯 RAG 시스템 성능 향상 방법을 알아보겠습니다!\\n\")\n",
        "\n",
        "# 1. 청크 크기 최적화 실험\n",
        "print(\"1️⃣ 청크 크기 최적화\")\n",
        "print(\"   현재 설정: chunk_size=1000, chunk_overlap=100\")\n",
        "\n",
        "# 다양한 청크 크기로 실험해볼 수 있는 함수\n",
        "def experiment_chunk_size(chunk_size, chunk_overlap):\n",
        "    \"\"\"다른 청크 크기로 실험해보기\"\"\"\n",
        "    print(f\"🧪 실험: chunk_size={chunk_size}, overlap={chunk_overlap}\")\n",
        "    \n",
        "    # 새로운 텍스트 분할기 생성\n",
        "    new_splitter = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=chunk_size,\n",
        "        chunk_overlap=chunk_overlap\n",
        "    )\n",
        "    \n",
        "    # 문서 재분할\n",
        "    new_splits = new_splitter.split_documents(docs)\n",
        "    print(f\"   생성된 청크 수: {len(new_splits)}개\")\n",
        "    \n",
        "    # 평균 청크 크기\n",
        "    avg_length = sum(len(chunk.page_content) for chunk in new_splits) / len(new_splits)\n",
        "    print(f\"   평균 청크 크기: {avg_length:.0f} 문자\")\n",
        "    \n",
        "    return new_splits\n",
        "\n",
        "# 예시 실험 (실제로 실행하려면 주석 해제)\n",
        "print(\"\\n💡 다른 설정으로 실험해보고 싶다면:\")\n",
        "print(\"new_splits = experiment_chunk_size(500, 50)  # 작은 청크\")\n",
        "print(\"new_splits = experiment_chunk_size(1500, 150)  # 큰 청크\")\n",
        "\n",
        "# 2. 검색 설정 최적화\n",
        "print(\"\\n2️⃣ 검색 설정 최적화\")\n",
        "print(\"   현재 설정: k=4 (4개 문서 반환)\")\n",
        "\n",
        "def create_custom_retriever(k=4, search_type=\"similarity\"):\n",
        "    \"\"\"커스텀 검색기 생성\"\"\"\n",
        "    return vectorstore.as_retriever(\n",
        "        search_type=search_type,\n",
        "        search_kwargs={\"k\": k}\n",
        "    )\n",
        "\n",
        "print(\"💡 다른 검색 설정 예시:\")\n",
        "print(\"retriever_k3 = create_custom_retriever(k=3)\")\n",
        "print(\"retriever_k6 = create_custom_retriever(k=6)\")\n",
        "\n",
        "# 3. 프롬프트 최적화\n",
        "print(\"\\n3️⃣ 프롬프트 최적화\")\n",
        "print(\"   현재: 일반적인 한국어 QA 프롬프트\")\n",
        "\n",
        "def create_custom_prompt(style=\"detailed\"):\n",
        "    \"\"\"다양한 스타일의 프롬프트 생성\"\"\"\n",
        "    if style == \"detailed\":\n",
        "        template = \"\"\"당신은 뉴스 분석 전문가입니다. 주어진 뉴스 기사를 바탕으로 상세하고 정확한 분석을 제공하세요.\n",
        "\n",
        "다음 지침을 따르세요:\n",
        "1. 주요 사실들을 정확히 파악하세요\n",
        "2. 중요한 수치나 날짜가 있다면 반드시 포함하세요  \n",
        "3. 객관적이고 중립적인 톤을 유지하세요\n",
        "4. 확실하지 않은 정보는 추측하지 마세요\n",
        "\n",
        "문맥: {context}\n",
        "질문: {question}\n",
        "\n",
        "분석:\"\"\"\n",
        "    \n",
        "    elif style == \"concise\":\n",
        "        template = \"\"\"간결하고 핵심만 담은 답변을 제공하세요.\n",
        "\n",
        "문맥: {context}\n",
        "질문: {question}\n",
        "\n",
        "답변 (3문장 이내):\"\"\"\n",
        "    \n",
        "    else:  # bullet_points\n",
        "        template = \"\"\"다음 형식으로 답변하세요:\n",
        "\n",
        "• 핵심 포인트 1\n",
        "• 핵심 포인트 2  \n",
        "• 핵심 포인트 3\n",
        "\n",
        "문맥: {context}\n",
        "질문: {question}\n",
        "\n",
        "답변:\"\"\"\n",
        "    \n",
        "    return PromptTemplate.from_template(template)\n",
        "\n",
        "print(\"💡 다른 프롬프트 스타일:\")\n",
        "print(\"detailed_prompt = create_custom_prompt('detailed')\")\n",
        "print(\"concise_prompt = create_custom_prompt('concise')\")\n",
        "print(\"bullet_prompt = create_custom_prompt('bullet_points')\")\n",
        "\n",
        "print(\"\\n✅ 성능 향상 팁 소개 완료!\")\n",
        "print(\"🚀 원하는 설정으로 실험해보세요!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
