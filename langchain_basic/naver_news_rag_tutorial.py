"""
ë„¤ì´ë²„ ë‰´ìŠ¤ ê¸°ë°˜ í•œêµ­ì–´ RAG íŠœí† ë¦¬ì–¼
====================================

ì´ íŠœí† ë¦¬ì–¼ì€ ë„¤ì´ë²„ ë‰´ìŠ¤ ê¸°ì‚¬ë¥¼ í™œìš©í•˜ì—¬ í•œêµ­ì–´ ê¸°ë°˜ì˜ RAG(Retrieval-Augmented Generation) 
ì‹œìŠ¤í…œì„ êµ¬ì¶•í•˜ëŠ” ë°©ë²•ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.

RAG íŒŒì´í”„ë¼ì¸:
1. ë¬¸ì„œ ë¡œë“œ(Document Loading): ë„¤ì´ë²„ ë‰´ìŠ¤ ê¸°ì‚¬ ì›¹ ìŠ¤í¬ë˜í•‘
2. í…ìŠ¤íŠ¸ ë¶„í• (Text Splitting): ë¬¸ì„œë¥¼ ì²­í¬ë¡œ ë¶„í• 
3. ì„ë² ë”©(Embedding): í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ë³€í™˜
4. ë²¡í„° ì €ì¥ì†Œ ìƒì„±(Vector Store): FAISSë¥¼ ì‚¬ìš©í•œ ë²¡í„° ì¸ë±ì‹±
5. ê²€ìƒ‰ê¸° ìƒì„±(Retriever): ìœ ì‚¬ì„± ê²€ìƒ‰ ì—”ì§„
6. í”„ë¡¬í”„íŠ¸ ìƒì„±(Prompt): í•œêµ­ì–´ ì§ˆë‹µì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸
7. ì–¸ì–´ëª¨ë¸(LLM): OpenAI GPT ëª¨ë¸
8. ì²´ì¸ ìƒì„±(Chain): ì „ì²´ RAG íŒŒì´í”„ë¼ì¸ ì—°ê²°

í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬:
- langchain
- langchain-community 
- langchain-openai
- langchain-text-splitters
- beautifulsoup4
- faiss-cpu
- python-dotenv
"""

import os
from dotenv import load_dotenv
import bs4
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.document_loaders import WebBaseLoader
from langchain_community.vectorstores import FAISS
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough
from langchain_core.prompts import PromptTemplate
from langchain_openai import ChatOpenAI, OpenAIEmbeddings


def setup_environment():
    """í™˜ê²½ ì„¤ì • ë° API í‚¤ ë¡œë“œ"""
    print("ğŸ”§ í™˜ê²½ ì„¤ì • ì¤‘...")
    load_dotenv()
    
    if not os.getenv("OPENAI_API_KEY"):
        print("âŒ OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        print("ğŸ’¡ .env íŒŒì¼ì— OPENAI_API_KEY=your_api_key ë¥¼ ì¶”ê°€í•˜ì„¸ìš”.")
        return False
    
    print("âœ… í™˜ê²½ ì„¤ì • ì™„ë£Œ!")
    return True


def load_naver_news(url):
    """
    ë„¤ì´ë²„ ë‰´ìŠ¤ ê¸°ì‚¬ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.
    
    Args:
        url (str): ë„¤ì´ë²„ ë‰´ìŠ¤ ê¸°ì‚¬ URL
        
    Returns:
        list: ë¡œë“œëœ ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸
    """
    print(f"ğŸ“° ë„¤ì´ë²„ ë‰´ìŠ¤ ë¡œë”© ì¤‘: {url}")
    
    # ë„¤ì´ë²„ ë‰´ìŠ¤ ê¸°ì‚¬ì˜ ë³¸ë¬¸ê³¼ ì œëª©ì„ ì¶”ì¶œí•˜ê¸° ìœ„í•œ CSS ì„ íƒì
    loader = WebBaseLoader(
        web_paths=(url,),
        bs_kwargs=dict(
            parse_only=bs4.SoupStrainer(
                "div",
                attrs={"class": ["newsct_article _article_body", "media_end_head_title"]},
            )
        ),
    )
    
    docs = loader.load()
    print(f"âœ… ë¬¸ì„œ ë¡œë“œ ì™„ë£Œ! ì´ {len(docs)}ê°œ ë¬¸ì„œ")
    
    if docs:
        print(f"ğŸ“„ ë¬¸ì„œ ë¯¸ë¦¬ë³´ê¸°: {docs[0].page_content[:200]}...")
    
    return docs


def split_documents(docs, chunk_size=1000, chunk_overlap=100):
    """
    ë¬¸ì„œë¥¼ ì‘ì€ ì²­í¬ë¡œ ë¶„í• í•©ë‹ˆë‹¤.
    
    Args:
        docs (list): ë¶„í• í•  ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸
        chunk_size (int): ê° ì²­í¬ì˜ ìµœëŒ€ í¬ê¸°
        chunk_overlap (int): ì²­í¬ ê°„ ê²¹ì¹˜ëŠ” ë¬¸ì ìˆ˜
        
    Returns:
        list: ë¶„í• ëœ ë¬¸ì„œ ì²­í¬ ë¦¬ìŠ¤íŠ¸
    """
    print(f"âœ‚ï¸ ë¬¸ì„œ ë¶„í•  ì¤‘... (ì²­í¬ í¬ê¸°: {chunk_size}, ê²¹ì¹¨: {chunk_overlap})")
    
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=chunk_size, 
        chunk_overlap=chunk_overlap
    )
    
    splits = text_splitter.split_documents(docs)
    print(f"âœ… ë¬¸ì„œ ë¶„í•  ì™„ë£Œ! ì´ {len(splits)}ê°œ ì²­í¬ ìƒì„±")
    
    return splits


def create_vectorstore(splits):
    """
    ë²¡í„° ì €ì¥ì†Œë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    
    Args:
        splits (list): ë¶„í• ëœ ë¬¸ì„œ ì²­í¬ ë¦¬ìŠ¤íŠ¸
        
    Returns:
        FAISS: FAISS ë²¡í„° ì €ì¥ì†Œ
    """
    print("ğŸ” ë²¡í„° ì €ì¥ì†Œ ìƒì„± ì¤‘... (ì„ë² ë”© ì²˜ë¦¬ ì¤‘)")
    
    # OpenAI ì„ë² ë”©ì„ ì‚¬ìš©í•˜ì—¬ ë²¡í„° ì €ì¥ì†Œ ìƒì„±
    vectorstore = FAISS.from_documents(
        documents=splits, 
        embedding=OpenAIEmbeddings()
    )
    
    print("âœ… ë²¡í„° ì €ì¥ì†Œ ìƒì„± ì™„ë£Œ!")
    return vectorstore


def create_rag_chain(vectorstore):
    """
    RAG ì²´ì¸ì„ ìƒì„±í•©ë‹ˆë‹¤.
    
    Args:
        vectorstore: ë²¡í„° ì €ì¥ì†Œ
        
    Returns:
        Chain: RAG ì²´ì¸
    """
    print("ğŸ”— RAG ì²´ì¸ ìƒì„± ì¤‘...")
    
    # ê²€ìƒ‰ê¸° ìƒì„±
    retriever = vectorstore.as_retriever()
    
    # í•œêµ­ì–´ ì§ˆë‹µì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
    prompt = PromptTemplate.from_template(
        """ë‹¹ì‹ ì€ ì§ˆë¬¸-ë‹µë³€(Question-Answering)ì„ ìˆ˜í–‰í•˜ëŠ” ì¹œì ˆí•œ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. 
ë‹¹ì‹ ì˜ ì„ë¬´ëŠ” ì£¼ì–´ì§„ ë¬¸ë§¥(context)ì—ì„œ ì£¼ì–´ì§„ ì§ˆë¬¸(question)ì— ë‹µí•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.

ê²€ìƒ‰ëœ ë‹¤ìŒ ë¬¸ë§¥(context)ì„ ì‚¬ìš©í•˜ì—¬ ì§ˆë¬¸(question)ì— ë‹µí•˜ì„¸ìš”. 
ë§Œì•½, ì£¼ì–´ì§„ ë¬¸ë§¥(context)ì—ì„œ ë‹µì„ ì°¾ì„ ìˆ˜ ì—†ë‹¤ë©´, 
`ì£¼ì–´ì§„ ì •ë³´ì—ì„œ ì§ˆë¬¸ì— ëŒ€í•œ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤`ë¼ê³  ë‹µí•˜ì„¸ìš”.

í•œê¸€ë¡œ ë‹µë³€í•´ ì£¼ì„¸ìš”. ë‹¨, ê¸°ìˆ ì ì¸ ìš©ì–´ë‚˜ ì´ë¦„ì€ ë²ˆì—­í•˜ì§€ ì•Šê³  ê·¸ëŒ€ë¡œ ì‚¬ìš©í•´ ì£¼ì„¸ìš”.

#Question: 
{question} 

#Context: 
{context} 

#Answer:"""
    )
    
    # LLM ëª¨ë¸ ì„¤ì •
    llm = ChatOpenAI(model_name="gpt-4o-mini", temperature=0)
    
    # RAG ì²´ì¸ ìƒì„±
    rag_chain = (
        {"context": retriever, "question": RunnablePassthrough()}
        | prompt
        | llm
        | StrOutputParser()
    )
    
    print("âœ… RAG ì²´ì¸ ìƒì„± ì™„ë£Œ!")
    return rag_chain


def ask_question(rag_chain, question):
    """
    RAG ì‹œìŠ¤í…œì— ì§ˆë¬¸ì„ í•©ë‹ˆë‹¤.
    
    Args:
        rag_chain: RAG ì²´ì¸
        question (str): ì§ˆë¬¸
        
    Returns:
        str: ë‹µë³€
    """
    print(f"\nâ“ ì§ˆë¬¸: {question}")
    print("ğŸ¤” ë‹µë³€ ìƒì„± ì¤‘...")
    
    try:
        response = rag_chain.invoke(question)
        print(f"ğŸ’¬ ë‹µë³€: {response}")
        return response
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None


def stream_response(rag_chain, question):
    """
    ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹ìœ¼ë¡œ ë‹µë³€ì„ ë°›ìŠµë‹ˆë‹¤.
    
    Args:
        rag_chain: RAG ì²´ì¸
        question (str): ì§ˆë¬¸
    """
    print(f"\nâ“ ì§ˆë¬¸: {question}")
    print("ğŸ’¬ ë‹µë³€: ", end="", flush=True)
    
    try:
        for chunk in rag_chain.stream(question):
            print(chunk, end="", flush=True)
        print()  # ì¤„ë°”ê¿ˆ
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("ğŸš€ ë„¤ì´ë²„ ë‰´ìŠ¤ ê¸°ë°˜ í•œêµ­ì–´ RAG íŠœí† ë¦¬ì–¼ ì‹œì‘!")
    print("=" * 60)
    
    # 1. í™˜ê²½ ì„¤ì •
    if not setup_environment():
        return
    
    # 2. ë„¤ì´ë²„ ë‰´ìŠ¤ URL (ì˜ˆì‹œ)
    # ì‹¤ì œ ì‚¬ìš©ì‹œì—ëŠ” ìµœì‹  ë‰´ìŠ¤ URLë¡œ ë³€ê²½í•˜ì„¸ìš”
    news_url = "https://n.news.naver.com/article/437/0000378416"
    
    try:
        # 3. ë¬¸ì„œ ë¡œë“œ
        docs = load_naver_news(news_url)
        if not docs:
            print("âŒ ë¬¸ì„œë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # 4. ë¬¸ì„œ ë¶„í• 
        splits = split_documents(docs)
        
        # 5. ë²¡í„° ì €ì¥ì†Œ ìƒì„±
        vectorstore = create_vectorstore(splits)
        
        # 6. RAG ì²´ì¸ ìƒì„±
        rag_chain = create_rag_chain(vectorstore)
        
        print("\n" + "=" * 60)
        print("ğŸ‰ RAG ì‹œìŠ¤í…œ êµ¬ì¶• ì™„ë£Œ! ì´ì œ ì§ˆë¬¸ì„ í•´ë³´ì„¸ìš”.")
        print("=" * 60)
        
        # 7. ì˜ˆì œ ì§ˆë¬¸ë“¤
        example_questions = [
            "ì´ ê¸°ì‚¬ì˜ ì£¼ìš” ë‚´ìš©ì„ ìš”ì•½í•´ì£¼ì„¸ìš”.",
            "ê¸°ì‚¬ì—ì„œ ì–¸ê¸‰ëœ ì£¼ìš” ì¸ë¬¼ì´ë‚˜ ê¸°ê´€ì€ ëˆ„êµ¬ì¸ê°€ìš”?",
            "ê¸°ì‚¬ì—ì„œ ë‹¤ë£¨ëŠ” ì£¼ìš” ì´ìŠˆëŠ” ë¬´ì—‡ì¸ê°€ìš”?",
            "ì´ ê¸°ì‚¬ê°€ ë‹¤ë£¨ëŠ” ë¶„ì•¼ë‚˜ ì£¼ì œëŠ” ë¬´ì—‡ì¸ê°€ìš”?"
        ]
        
        # ì˜ˆì œ ì§ˆë¬¸ ì‹¤í–‰
        for question in example_questions:
            ask_question(rag_chain, question)
            print("-" * 40)
        
        # 8. ëŒ€í™”í˜• ì§ˆë¬¸ ëª¨ë“œ
        print("\nğŸ—£ï¸ ëŒ€í™”í˜• ëª¨ë“œë¥¼ ì‹œì‘í•©ë‹ˆë‹¤. 'quit' ë˜ëŠ” 'ì¢…ë£Œ'ë¥¼ ì…ë ¥í•˜ë©´ ì¢…ë£Œë©ë‹ˆë‹¤.")
        print("-" * 60)
        
        while True:
            user_question = input("\nì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”: ").strip()
            
            if user_question.lower() in ['quit', 'ì¢…ë£Œ', 'exit', 'q']:
                print("ğŸ‘‹ íŠœí† ë¦¬ì–¼ì„ ì¢…ë£Œí•©ë‹ˆë‹¤. ê°ì‚¬í•©ë‹ˆë‹¤!")
                break
            
            if not user_question:
                print("ğŸ’¡ ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                continue
            
            # ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹ìœ¼ë¡œ ë‹µë³€ ì¶œë ¥
            stream_response(rag_chain, user_question)
        
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        print("ğŸ’¡ ì¸í„°ë„· ì—°ê²°, API í‚¤, ë˜ëŠ” ë‰´ìŠ¤ URLì„ í™•ì¸í•´ì£¼ì„¸ìš”.")


def demo_with_custom_url():
    """
    ì‚¬ìš©ì ì •ì˜ URLë¡œ ë°ëª¨ë¥¼ ì‹¤í–‰í•˜ëŠ” í•¨ìˆ˜
    """
    print("ğŸ”§ ì‚¬ìš©ì ì •ì˜ URL ë°ëª¨")
    
    if not setup_environment():
        return
    
    print("ğŸ“ ë„¤ì´ë²„ ë‰´ìŠ¤ URLì„ ì…ë ¥í•˜ì„¸ìš”:")
    print("ì˜ˆì‹œ: https://n.news.naver.com/article/437/0000378416")
    
    url = input("URL: ").strip()
    
    if not url.startswith("https://n.news.naver.com/"):
        print("âŒ ì˜¬ë°”ë¥¸ ë„¤ì´ë²„ ë‰´ìŠ¤ URLì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        return
    
    try:
        docs = load_naver_news(url)
        splits = split_documents(docs)
        vectorstore = create_vectorstore(splits)
        rag_chain = create_rag_chain(vectorstore)
        
        print("\nâœ… ì„¤ì • ì™„ë£Œ! ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”.")
        
        while True:
            question = input("\nì§ˆë¬¸ (ì¢…ë£Œ: quit): ").strip()
            if question.lower() in ['quit', 'ì¢…ë£Œ']:
                break
            
            if question:
                stream_response(rag_chain, question)
    
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜: {e}")


if __name__ == "__main__":
    print("ğŸŒŸ ë„¤ì´ë²„ ë‰´ìŠ¤ RAG íŠœí† ë¦¬ì–¼")
    print("1. ê¸°ë³¸ ë°ëª¨ ì‹¤í–‰")
    print("2. ì‚¬ìš©ì ì •ì˜ URLë¡œ ì‹¤í–‰")
    
    choice = input("ì„ íƒí•˜ì„¸ìš” (1 ë˜ëŠ” 2): ").strip()
    
    if choice == "1":
        main()
    elif choice == "2":
        demo_with_custom_url()
    else:
        print("ì˜¬ë°”ë¥¸ ì„ íƒì§€ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
